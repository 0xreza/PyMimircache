# coding=utf-8
"""
this module plots the HRC of the complete trace for a datacenter and manually splitted traces for each node 
the cache size is equally splitted on each node 
the complete trace can be generated by combineSplittedTrace.py 
"""

from PyMimircache import *
from collections import deque, defaultdict
from PyMimircache.utils.printing import printList
import csv
import math
from matplotlib import pyplot as plt

import os, sys, time, pickle
from multiprocessing import Pool, Process, cpu_count
from functools import partial
sys.path.append("../")
sys.path.append("./")
from PyMimircache import *
import PyMimircache.CMimircache.Heatmap as c_heatmap
from PyMimircache.bin.conf import *
from PyMimircache.A1a1a11a.ML.featureGenerator import *

################################## Global variable and initialization ###################################

TRACE_TYPE = "Akamai"
TRACE_DIR, NUM_OF_THREADS = initConf(TRACE_TYPE, trace_format=None)


TRACE_DIR = "/root/disk2/ALL_DATA/Akamai/"
t_virtual = 2000  # 60 * 1000000
t_real = 60 * 1000000
NUM_OF_BINS = 8

BINARY_INIT_PARAMS = {"label": 2, "fmt": "<LL"}


def run(complete_trace, splitted_traces, dat_name, cache="LRU", cache_size=-1, no_clf=False):
    SIZE_MULTIPLIER = len(splitted_traces)
    if SIZE_MULTIPLIER == 0:
        return
    reader_complete = BinaryReader(complete_trace, init_params=BINARY_INIT_PARAMS)

    if cache_size == -1:
        cache_size = len(reader_complete)
    CACHE_SIZE_SPLITTED = cache_size//SIZE_MULTIPLIER
    CACHE_SIZE_COMPLETE = CACHE_SIZE_SPLITTED * SIZE_MULTIPLIER

    if cache == "LRU":
        profilerC = partial(LRUProfiler, cache_size=CACHE_SIZE_COMPLETE)
        profilerS = partial(LRUProfiler, cache_size=CACHE_SIZE_SPLITTED)
        BIN_SIZE = 1
    else:
        BIN_SIZE = CACHE_SIZE_SPLITTED // NUM_OF_BINS
        profilerC = partial(cGeneralProfiler, cache_name=cache, cache_size=CACHE_SIZE_COMPLETE,
                           num_of_threads=8, bin_size=BIN_SIZE)
        profilerS = partial(cGeneralProfiler, cache_name=cache, cache_size=CACHE_SIZE_SPLITTED,
                           num_of_threads=8, bin_size=BIN_SIZE)

    p_complete = profilerC(reader_complete)
    hc_complete_np = p_complete.get_hit_count()
    print('complete file hit count got, len {}'.format(len(hc_complete_np)))

    LENGTH = len(reader_complete)

    hc_splitted = [0] * len(hc_complete_np)
    hr_splitted_individual = []
    hc_complete = hc_complete_np.tolist()


    for f in splitted_traces:
        print(f)
        reader_splitted = BinaryReader(f, init_params=BINARY_INIT_PARAMS)
        p_splitted = profilerS(reader_splitted)
        hc_f = p_splitted.get_hit_count()

        hr_f = [0] * len(hc_f)
        for i in range(1, len(hc_f)):
            hr_f[i] = hr_f[i-1] + hc_f[i]/len(reader_splitted)
        hr_splitted_individual.append(hr_f)
        plt.plot([BIN_SIZE*i for i in range(len(hr_f)-2)],
                 hr_f[:-2], label="{} {}".format(cache, f[f.rfind('/')+1:]))

        for n in range(len(hc_f)-2):
            if n * SIZE_MULTIPLIER < len(hc_complete_np):
                hc_splitted[n * SIZE_MULTIPLIER] += hc_f[n]
            else:
                print("splitted trace hc idx({}) out of range".format(n))
    print(time.time())
    for hc in [hc_complete, hc_splitted]:
        hc[0] = hc[0] / LENGTH
        for i in range(1, len(hc)-1):
            hc[i] = hc[i-1] + hc[i]/LENGTH
    print(time.time())

    plt.plot([BIN_SIZE*i for i in range(len(hc_complete)-2)], hc_complete[:-2], label="{} complete".format(cache))
    plt.plot([BIN_SIZE*i for i in range(len(hc_splitted)-2)], hc_splitted[:-2], label="{} splitted".format(cache))
    plt.ylabel("Hit Ratio")
    plt.xlabel("Cache Size/items")

    plt.legend(loc='best')
    plt.savefig("{}_{}.pdf".format(dat_name, cache))

    if not no_clf:
        plt.clf()


def batch_dbbd2():
    for folder in os.listdir(TRACE_DIR):
        if os.path.isfile("{}/{}".format(TRACE_DIR, folder)):
            continue

        run("{}/{}/complete".format(TRACE_DIR, folder),
            ["{}/{}/{}".format(TRACE_DIR, folder, f)
             for f in os.listdir("{}/{}/".format(TRACE_DIR, folder))
             if os.path.isfile("{}/{}/{}".format(TRACE_DIR, folder, f))
             and f!='complete'], dat_name=folder,
            no_clf=True, cache_size=1000000)

        run("{}/{}/complete".format(TRACE_DIR, folder),
            ["{}/{}/{}".format(TRACE_DIR, folder, f)
             for f in os.listdir("{}/{}/".format(TRACE_DIR, folder))
             if os.path.isfile("{}/{}/{}".format(TRACE_DIR, folder, f))
             and f!='complete'], dat_name=folder,
            cache="Optimal", cache_size=1000000)



if __name__ == "__main__":
    folder = "1203"
    run("{}/{}/complete".format(TRACE_DIR, folder),
        ["{}/{}/{}".format(TRACE_DIR, folder, f)
         for f in os.listdir("{}/{}/".format(TRACE_DIR, folder))
         if os.path.isfile("{}/{}/{}".format(TRACE_DIR, folder, f))
         and f != 'complete'], dat_name=folder,
        no_clf=True, cache_size=-1)






